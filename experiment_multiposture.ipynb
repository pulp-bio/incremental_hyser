{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from ztbiocas.datasets import uniboinail as ui\n",
    "from ztbiocas.learning import mlpuniboinail as mui\n",
    "from ztbiocas.learning import settings as learnset\n",
    "from ztbiocas.learning import learning as learn\n",
    "from ztbiocas.analysis import goodness as good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_REPETITIONS = 1\n",
    "\n",
    "DOWNSAMPLING_FACTOR = 1\n",
    "\n",
    "NUM_TRAIN_REPETITIONS = 5\n",
    "\n",
    "NUM_EPOCHS_FP = 4\n",
    "\n",
    "RESULTS_FILENAME = 'results_multitrain_replication.pkl'\n",
    "RESULTS_DIR_PATH = './results/'\n",
    "RESULTS_FILE_FULLPATH = RESULTS_DIR_PATH + RESULTS_FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure for storing the results\n",
    "\n",
    "results = {\n",
    "    'num_repetitions': NUM_REPETITIONS,\n",
    "    'repetition': {},\n",
    "}\n",
    "\n",
    "\n",
    "for idx_repetition in range(NUM_REPETITIONS):\n",
    "    results['repetition'][idx_repetition] = {'subject': {}}\n",
    "\n",
    "    for idx_subject in range(ui.NUM_SUBJECTS):\n",
    "\n",
    "        results['repetition'][idx_repetition]['subject'][idx_subject] = {'day': {}}\n",
    "\n",
    "        for idx_day in range(ui.NUM_DAYS):\n",
    "\n",
    "            results['repetition'][idx_repetition]['subject'][idx_subject]['day'][idx_day] = {'posture': {}}\n",
    "\n",
    "            for idx_valid_posture in range(ui.NUM_POSTURES):\n",
    "\n",
    "                results['repetition'][idx_repetition]['subject'][idx_subject]['day'][idx_day]['posture'][idx_valid_posture] = {\n",
    "                    # just classification metrics, no models or labels\n",
    "                    'training': {},  # classification metrics dictionary\n",
    "                    'validation': {},  # classification metrics dictionary\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnset.set_reproducibility()\n",
    "\n",
    "\n",
    "for idx_repetition, idx_subject, idx_day in itertools.product(\n",
    "    range(NUM_REPETITIONS), range(ui.NUM_SUBJECTS), range(ui.NUM_DAYS)\n",
    "):\n",
    "    \n",
    "    # ----------------------------------------------------------------------- #\n",
    "\n",
    "    # print a header\n",
    "    print(\n",
    "        f\"\\n\"\n",
    "        f\"------------------------------------------------------------------\\n\"\n",
    "        f\"REPETITION\\t{idx_repetition + 1 :d}/{NUM_REPETITIONS:d}\\n\"\n",
    "        f\"SUBJECT\\t{idx_subject + 1 :d}/{ui.NUM_SUBJECTS:d}\\n\"\n",
    "        f\"DAY\\t{idx_day + 1 :d}/{ui.NUM_DAYS:d}\\n\"\n",
    "        f\"(all indices are one-based)\\n\"\n",
    "        f\"------------------------------------------------------------------\\n\"\n",
    "        f\"\\n\"\n",
    "    )\n",
    "\n",
    "    # ----------------------------------------------------------------------- #\n",
    "\n",
    "    # load training data\n",
    "\n",
    "    xtrain_list = []\n",
    "    ytrain_list = []\n",
    "\n",
    "    for idx_train_posture in range(ui.NUM_POSTURES):\n",
    "        \n",
    "        train_session_data_dict = ui.load_session(\n",
    "            idx_subject, idx_day, idx_train_posture)\n",
    "\n",
    "        emg_train = train_session_data_dict['emg']\n",
    "        relabel_train = train_session_data_dict['relabel']\n",
    "        gesture_counter_train = train_session_data_dict['gesture_counter']\n",
    "        del train_session_data_dict\n",
    "\n",
    "        # \"_p\" stands for single posture\n",
    "        xtrain_p, ytrain_p, _, _ = ui.split_into_calib_and_valid(\n",
    "            emg=emg_train,\n",
    "            relabel=relabel_train,\n",
    "            gesture_counter=gesture_counter_train,\n",
    "            num_calib_repetitions=NUM_TRAIN_REPETITIONS,\n",
    "        )\n",
    "        del emg_train, relabel_train, gesture_counter_train\n",
    "\n",
    "        # add to the lists\n",
    "        xtrain_list.append(xtrain_p)\n",
    "        ytrain_list.append(ytrain_p)\n",
    "        del xtrain_p, ytrain_p\n",
    "\n",
    "    # concatenate into single arrays\n",
    "    xtrain = np.concatenate(xtrain_list, axis=1)\n",
    "    ytrain = np.concatenate(ytrain_list, axis=0)\n",
    "    del xtrain_list, ytrain_list\n",
    "\n",
    "    # ----------------------------------------------------------------------- #\n",
    "\n",
    "    # downsampling\n",
    "    xtrain = xtrain[:, ::DOWNSAMPLING_FACTOR]\n",
    "    ytrain = ytrain[::DOWNSAMPLING_FACTOR]\n",
    "\n",
    "    # standard scaling and de-correlation, as preprocessing before training\n",
    "    stdscaler_train = StandardScaler()\n",
    "    xtrain_stdscaled = stdscaler_train.fit_transform(xtrain.T).T\n",
    "    del xtrain\n",
    "    pca_train = PCA(n_components=ui.NUM_CHANNELS, whiten=False)\n",
    "    xtrain_pc = pca_train.fit_transform(xtrain_stdscaled.T).T\n",
    "    del xtrain_stdscaled\n",
    "\n",
    "    # ----------------------------------------------------------------------- #\n",
    "\n",
    "    # MLP training and validation\n",
    "\n",
    "    mlp = mui.MLPUniboINAIL(\n",
    "        num_input=ui.NUM_CHANNELS, num_hidden=8, num_output=ui.NUM_CLASSES)\n",
    "    mui.summarize(mlp, num_input=ui.NUM_CHANNELS)\n",
    "\n",
    "    # full-precision training\n",
    "    mlp, history, yout_train, yout_valid = learn.do_training(\n",
    "        xtrain=xtrain_pc,\n",
    "        ytrain=ytrain,\n",
    "        model=mlp,\n",
    "        xvalid=None,\n",
    "        yvalid=None,\n",
    "        num_epochs=NUM_EPOCHS_FP,\n",
    "        mltask=learn.MLTask.CLASSIFICATION,\n",
    "        num_classes=ui.NUM_CLASSES,\n",
    "    )    \n",
    "    del xtrain_pc, ytrain\n",
    "    \n",
    "    # ----------------------------------------------------------------------- #\n",
    "\n",
    "    for idx_valid_posture in range(ui.NUM_POSTURES):\n",
    "\n",
    "        # ------------------------------------------------------------------- #\n",
    "\n",
    "        # print a header\n",
    "        print(\n",
    "            f\"\\n\"\n",
    "            f\"--------------------------------------------------------------\\n\"\n",
    "            f\"VALIDATION ON POSTURE {idx_valid_posture + 1 :d}\\n\"\n",
    "            f\"--------------------------------------------------------------\\n\"\n",
    "            f\"\\n\"\n",
    "        )\n",
    "\n",
    "        # ------------------------------------------------------------------- #\n",
    "        \n",
    "        # load validation data\n",
    "\n",
    "        valid_session_data_dict = ui.load_session(\n",
    "            idx_subject, idx_day, idx_valid_posture)\n",
    "\n",
    "        emg_valid = valid_session_data_dict['emg']\n",
    "        relabel_valid = valid_session_data_dict['relabel']\n",
    "        gesture_counter_valid = valid_session_data_dict['gesture_counter']\n",
    "        del valid_session_data_dict\n",
    "\n",
    "        # \"_p\" stands for single posture\n",
    "        xtrain_p, ytrain_p, xvalid, yvalid = ui.split_into_calib_and_valid(\n",
    "            emg=emg_valid,\n",
    "            relabel=relabel_valid,\n",
    "            gesture_counter=gesture_counter_valid,\n",
    "            num_calib_repetitions=NUM_TRAIN_REPETITIONS,\n",
    "        )\n",
    "        del emg_valid, relabel_valid, gesture_counter_valid\n",
    "\n",
    "        # ------------------------------------------------------------------- #\n",
    "\n",
    "        # preprocessing\n",
    "\n",
    "        xtrain_p = xtrain_p[:, ::DOWNSAMPLING_FACTOR]\n",
    "        ytrain_p = ytrain_p[::DOWNSAMPLING_FACTOR]\n",
    "        xvalid = xvalid[:, ::DOWNSAMPLING_FACTOR]\n",
    "        yvalid = yvalid[::DOWNSAMPLING_FACTOR]\n",
    "\n",
    "        xtrain_p_standardscaled = stdscaler_train.transform(xtrain_p.T).T\n",
    "        xvalid_standardscaled = stdscaler_train.transform(xvalid.T).T\n",
    "        del xtrain_p, xvalid\n",
    "        xtrain_p_pc = pca_train.transform(xtrain_p_standardscaled.T).T\n",
    "        xvalid_pc = pca_train.transform(xvalid_standardscaled.T).T\n",
    "        del xtrain_p_standardscaled, xvalid_standardscaled\n",
    "\n",
    "        # ------------------------------------------------------------------- #\n",
    "\n",
    "        # MLP inference\n",
    "        \n",
    "        yout_train_p = learn.do_inference(xtrain_p_pc, mlp)\n",
    "        yout_valid = learn.do_inference(xvalid_pc, mlp)\n",
    "        del xtrain_p_pc, xvalid_pc\n",
    "\n",
    "        metrics_train_p = good.compute_classification_metrics(ytrain_p, yout_train_p)\n",
    "        metrics_valid = good.compute_classification_metrics(yvalid, yout_valid)\n",
    "\n",
    "        print(\"\\n\\n\")\n",
    "        print(\"On training repetitions:\")\n",
    "        print(metrics_train_p)\n",
    "        print(\"On validation repetitions:\")\n",
    "        print(metrics_valid)\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        # ------------------------------------------------------------------- #\n",
    "\n",
    "        # store results\n",
    "        results['repetition'][idx_repetition]['subject'][idx_subject]['day'][idx_day]['posture'][idx_valid_posture]['training'] = metrics_train_p\n",
    "        results['repetition'][idx_repetition]['subject'][idx_subject]['day'][idx_day]['posture'][idx_valid_posture]['validation'] = metrics_valid\n",
    "        \n",
    "        # ------------------------------------------------------------------- #\n",
    "\n",
    "        # save to file\n",
    "        # save the updated results dictionary after each validation\n",
    "        results_outer_dict = {'results': results}\n",
    "        Path(RESULTS_DIR_PATH).mkdir(parents=True, exist_ok=True)\n",
    "        with open(RESULTS_FILE_FULLPATH, 'wb') as f:\n",
    "            pickle.dump(results_outer_dict, f)\n",
    "\n",
    "        # ------------------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1/4\t\t0.3015\t0.8840\t\tnone\tnone\t\t5.4\n",
    "2/4\t\t0.2468\t0.9058\t\tnone\tnone\t\t4.7\n",
    "3/4\t\t0.2405\t0.9093\t\tnone\tnone\t\t4.7\n",
    "4/4\t\t0.2357\t0.9116\t\tnone\tnone\t\t4.7\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "1/4\t\t0.3015\t0.8840\t\tnone\tnone\t\t5.3\n",
    "2/4\t\t0.2468\t0.9058\t\tnone\tnone\t\t4.9\n",
    "3/4\t\t0.2405\t0.9093\t\tnone\tnone\t\t5.7\n",
    "4/4\t\t0.2357\t0.9116\t\tnone\tnone\t\t4.8\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantlib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
